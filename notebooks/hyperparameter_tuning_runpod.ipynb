{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Optuna - RunPod GPU\n",
    "\n",
    "Uses Optuna to find optimal PPO hyperparameters.\n",
    "\n",
    "**Search Space:**\n",
    "- learning_rate: 1e-5 to 1e-3 (log scale)\n",
    "- n_steps: [1024, 2048, 4096]\n",
    "- batch_size: [32, 64, 128]\n",
    "- n_epochs: [5, 10, 15]\n",
    "- gamma: 0.95 to 0.999\n",
    "- ent_coef: 0.001 to 0.1 (log scale)\n",
    "- net_arch_size: [64, 128, 256]\n",
    "\n",
    "**Strategy:**\n",
    "- 300k timesteps per trial (vs 1.5M for final training)\n",
    "- ~10 min per trial\n",
    "- 25 trials = ~4 hours\n",
    "- Pruning enabled to skip bad trials early"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU only'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone/update repository\n",
    "import os\n",
    "if not os.path.exists('/workspace/enhanced-rl-portfolio'):\n",
    "    !git clone https://github.com/nimeshk03/enhanced-rl-portfolio.git /workspace/enhanced-rl-portfolio\n",
    "else:\n",
    "    !cd /workspace/enhanced-rl-portfolio && git pull\n",
    "\n",
    "os.chdir('/workspace/enhanced-rl-portfolio')\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q stable-baselines3[extra] gymnasium pandas numpy pyyaml tensorboard optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data files\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "price_exists = os.path.exists('data/processed_data.csv')\n",
    "sentiment_exists = os.path.exists('data/historical_sentiment_complete.csv')\n",
    "\n",
    "if price_exists and sentiment_exists:\n",
    "    print(\"Data files found!\")\n",
    "else:\n",
    "    print(\"Missing data files - upload before continuing:\")\n",
    "    if not price_exists: print(\"  - data/processed_data.csv\")\n",
    "    if not sentiment_exists: print(\"  - data/historical_sentiment_complete.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "N_TRIALS = 25          # Number of trials (25 recommended, ~4 hours)\n",
    "TIMESTEPS = 300_000    # Timesteps per trial (reduced for speed)\n",
    "\n",
    "print(f\"Trials: {N_TRIALS}\")\n",
    "print(f\"Timesteps per trial: {TIMESTEPS:,}\")\n",
    "print(f\"Estimated time: ~{N_TRIALS * 10} minutes ({N_TRIALS * 10 / 60:.1f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hyperparameter search\n",
    "!python -m src.experiments.hyperparameter_search --n-trials {N_TRIALS} --timesteps {TIMESTEPS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load best hyperparameters\n",
    "with open('experiments/optuna_study/best_hyperparameters.json', 'r') as f:\n",
    "    best = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BEST HYPERPARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Sharpe: {best['best_sharpe']:.4f}\")\n",
    "print(f\"\\nParameters:\")\n",
    "for k, v in best['best_params'].items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "if 'best_metrics' in best:\n",
    "    print(f\"\\nAdditional Metrics:\")\n",
    "    for k, v in best['best_metrics'].items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all trials\n",
    "df = pd.read_csv('experiments/optuna_study/all_trials.csv')\n",
    "\n",
    "print(\"Top 10 Trials:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "top_10 = df.nlargest(10, 'value')[['number', 'value', 'params_learning_rate', 'params_ent_coef', 'params_net_arch_size']]\n",
    "top_10.columns = ['Trial', 'Sharpe', 'LR', 'Ent Coef', 'Net Size']\n",
    "print(top_10.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Sharpe over trials\n",
    "ax = axes[0, 0]\n",
    "ax.plot(df['number'], df['value'], 'b-', alpha=0.5)\n",
    "ax.scatter(df['number'], df['value'], c='blue', alpha=0.5)\n",
    "ax.axhline(y=df['value'].max(), color='r', linestyle='--', label=f'Best: {df[\"value\"].max():.3f}')\n",
    "ax.set_xlabel('Trial')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.set_title('Sharpe Ratio Over Trials')\n",
    "ax.legend()\n",
    "\n",
    "# Learning rate vs Sharpe\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(df['params_learning_rate'], df['value'], alpha=0.6)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Learning Rate')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.set_title('Learning Rate vs Sharpe')\n",
    "\n",
    "# Entropy coef vs Sharpe\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(df['params_ent_coef'], df['value'], alpha=0.6)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Entropy Coefficient')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.set_title('Entropy Coef vs Sharpe')\n",
    "\n",
    "# Network size vs Sharpe\n",
    "ax = axes[1, 1]\n",
    "for size in [64, 128, 256]:\n",
    "    mask = df['params_net_arch_size'] == size\n",
    "    ax.scatter([size]*mask.sum(), df.loc[mask, 'value'], alpha=0.6, label=f'{size}')\n",
    "ax.set_xlabel('Network Size')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.set_title('Network Size vs Sharpe')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiments/optuna_study/optimization_plots.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved to experiments/optuna_study/optimization_plots.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Final Model with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train full model with best hyperparameters\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "sys.path.insert(0, '.')\n",
    "from src.env.enhanced_portfolio_env import EnhancedPortfolioEnv\n",
    "from src.data.enhanced_processor import EnhancedDataProcessor, ProcessorConfig\n",
    "\n",
    "# Load best params\n",
    "with open('experiments/optuna_study/best_hyperparameters.json', 'r') as f:\n",
    "    best = json.load(f)\n",
    "\n",
    "params = best['best_params']\n",
    "print(\"Training with best hyperparameters:\")\n",
    "for k, v in params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def prepare_df_for_env(df):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "    dates = sorted(df['date'].unique())\n",
    "    date_to_day = {date: i for i, date in enumerate(dates)}\n",
    "    df['day'] = df['date'].map(date_to_day)\n",
    "    return df.set_index('day')\n",
    "\n",
    "processor = EnhancedDataProcessor(\n",
    "    price_path='data/processed_data.csv',\n",
    "    sentiment_path='data/historical_sentiment_complete.csv',\n",
    "    config=ProcessorConfig(normalize_features=True, normalization_window=60),\n",
    ")\n",
    "\n",
    "train_df, test_df = processor.get_train_test_split(\n",
    "    train_end=\"2024-06-30\",\n",
    "    test_start=\"2024-07-01\",\n",
    "    test_end=\"2025-11-30\",\n",
    ")\n",
    "\n",
    "feature_info = processor.get_feature_info()\n",
    "train_df_indexed = prepare_df_for_env(train_df)\n",
    "test_df_indexed = prepare_df_for_env(test_df)\n",
    "\n",
    "print(f\"Train: {len(train_df)} records\")\n",
    "print(f\"Test: {len(test_df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment and train\n",
    "TOTAL_TIMESTEPS = 1_500_000\n",
    "\n",
    "env_config = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 100000,\n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.001,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"sentiment_reward_weight\": 0.0,\n",
    "}\n",
    "\n",
    "train_env = EnhancedPortfolioEnv(\n",
    "    df=train_df_indexed,\n",
    "    stock_dim=feature_info['n_tickers'],\n",
    "    tech_indicator_list=feature_info['tech_indicators'],\n",
    "    sentiment_feature_list=feature_info['sentiment_features'],\n",
    "    include_sentiment=True,\n",
    "    normalize_obs=False,\n",
    "    print_verbosity=0,\n",
    "    **env_config,\n",
    ")\n",
    "\n",
    "train_env_wrapped = DummyVecEnv([lambda: Monitor(train_env)])\n",
    "\n",
    "# Create model with best params\n",
    "net_size = params['net_arch_size']\n",
    "policy_kwargs = {\"net_arch\": dict(pi=[net_size, net_size], vf=[net_size, net_size])}\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    train_env_wrapped,\n",
    "    learning_rate=params['learning_rate'],\n",
    "    n_steps=params['n_steps'],\n",
    "    batch_size=params['batch_size'],\n",
    "    n_epochs=params['n_epochs'],\n",
    "    gamma=params['gamma'],\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=params['ent_coef'],\n",
    "    vf_coef=params['vf_coef'],\n",
    "    max_grad_norm=params['max_grad_norm'],\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining for {TOTAL_TIMESTEPS:,} timesteps...\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "model.learn(total_timesteps=TOTAL_TIMESTEPS, progress_bar=True)\n",
    "\n",
    "training_time = datetime.now() - start_time\n",
    "print(f\"\\nTraining completed in {training_time}\")\n",
    "\n",
    "# Save model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "model.save('models/ppo_enhanced_tuned')\n",
    "print(\"Model saved to models/ppo_enhanced_tuned.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned model\n",
    "test_env = EnhancedPortfolioEnv(\n",
    "    df=test_df_indexed,\n",
    "    stock_dim=feature_info['n_tickers'],\n",
    "    tech_indicator_list=feature_info['tech_indicators'],\n",
    "    sentiment_feature_list=feature_info['sentiment_features'],\n",
    "    include_sentiment=True,\n",
    "    normalize_obs=False,\n",
    "    print_verbosity=0,\n",
    "    **env_config,\n",
    ")\n",
    "\n",
    "obs, _ = test_env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(obs.reshape(1, -1), deterministic=True)\n",
    "    obs, _, done, _, _ = test_env.step(action[0])\n",
    "\n",
    "stats = test_env.get_portfolio_stats()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TUNED MODEL - TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final Portfolio Value: ${stats['final_value']:,.2f}\")\n",
    "print(f\"Total Return: {stats['total_return']*100:.2f}%\")\n",
    "print(f\"Sharpe Ratio: {stats['sharpe_ratio']:.3f}\")\n",
    "print(f\"Max Drawdown: {stats['max_drawdown']*100:.2f}%\")\n",
    "print(f\"Total Trades: {stats['total_trades']}\")\n",
    "\n",
    "# Compare with v2 baseline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON WITH V2 (lr=3e-4, batch=128)\")\n",
    "print(\"=\"*60)\n",
    "v2_sharpe = 1.221\n",
    "v2_return = 41.12\n",
    "print(f\"V2 Sharpe: {v2_sharpe:.3f} -> Tuned: {stats['sharpe_ratio']:.3f} ({stats['sharpe_ratio']-v2_sharpe:+.3f})\")\n",
    "print(f\"V2 Return: {v2_return:.2f}% -> Tuned: {stats['total_return']*100:.2f}% ({stats['total_return']*100-v2_return:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip of all results\n",
    "!zip -r /workspace/hyperparameter_tuning_results.zip experiments/optuna_study/ models/ppo_enhanced_tuned.zip\n",
    "\n",
    "print(\"\\nDownload: /workspace/hyperparameter_tuning_results.zip\")\n",
    "print(\"Use RunPod File Browser or SCP\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REMEMBER: Stop your RunPod instance to avoid charges!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
