{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Production Model Training\n",
    "\n",
    "**Purpose:** Train the final production model using:\n",
    "- **Baseline configuration** (no sentiment features - best performer from ablation)\n",
    "- **Optuna-tuned hyperparameters** (Sharpe 2.28)\n",
    "\n",
    "**Expected Results:**\n",
    "- Sharpe Ratio: ~1.6-2.0\n",
    "- Total Return: ~45-55%\n",
    "- Max Drawdown: <15%\n",
    "\n",
    "**Training Time:** ~40 minutes on RTX 4090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = \"https://github.com/nimeshk03/enhanced-rl-portfolio.git\"\n",
    "WORK_DIR = \"/workspace/enhanced-rl-portfolio\"\n",
    "\n",
    "if os.path.exists(WORK_DIR):\n",
    "    print(\"Repository exists, pulling latest...\")\n",
    "    os.chdir(WORK_DIR)\n",
    "    subprocess.run([\"git\", \"pull\"], check=True)\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    os.chdir(\"/workspace\")\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL], check=True)\n",
    "    os.chdir(WORK_DIR)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q stable-baselines3 gymnasium pandas numpy pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "sys.path.insert(0, \"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "from src.data.enhanced_processor import EnhancedDataProcessor\n",
    "\n",
    "processor = EnhancedDataProcessor(\n",
    "    price_path=\"data/processed_data.csv\",\n",
    "    sentiment_path=\"data/historical_sentiment_complete.csv\"\n",
    ")\n",
    "\n",
    "train_data, test_data = processor.get_train_test_split(\n",
    "    train_end=\"2024-06-30\",\n",
    "    test_start=\"2024-07-01\"\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(train_data)} records\")\n",
    "print(f\"Test: {len(test_data)} records\")\n",
    "print(f\"Train period: {train_data['date'].min()} to {train_data['date'].max()}\")\n",
    "print(f\"Test period: {test_data['date'].min()} to {test_data['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "sys.path.insert(0, \"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from src.env.enhanced_portfolio_env import EnhancedPortfolioEnv\n",
    "from src.data.enhanced_processor import EnhancedDataProcessor\n",
    "\n",
    "EXPERIMENT_NAME = \"final_production_model\"\n",
    "TOTAL_TIMESTEPS = 1_500_000\n",
    "\n",
    "TUNED_HYPERPARAMETERS = {\n",
    "    \"learning_rate\": 0.000812,\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"gamma\": 0.992,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"ent_coef\": 0.0024,\n",
    "    \"vf_coef\": 0.428,\n",
    "    \"max_grad_norm\": 0.769,\n",
    "}\n",
    "\n",
    "POLICY_KWARGS = {\"net_arch\": [256, 256]}\n",
    "\n",
    "processor = EnhancedDataProcessor(\n",
    "    price_path=\"data/processed_data.csv\",\n",
    "    sentiment_path=\"data/historical_sentiment_complete.csv\"\n",
    ")\n",
    "train_data, test_data = processor.get_train_test_split(\n",
    "    train_end=\"2024-06-30\",\n",
    "    test_start=\"2024-07-01\"\n",
    ")\n",
    "\n",
    "TECH_INDICATORS = [\n",
    "    'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30',\n",
    "    'close_30_sma', 'close_60_sma', 'vix', 'turbulence'\n",
    "]\n",
    "\n",
    "def create_env(data, mode=\"train\"):\n",
    "    return EnhancedPortfolioEnv(\n",
    "        df=data,\n",
    "        stock_dim=10,\n",
    "        hmax=100,\n",
    "        initial_amount=100000,\n",
    "        buy_cost_pct=0.001,\n",
    "        sell_cost_pct=0.001,\n",
    "        reward_scaling=1e-4,\n",
    "        tech_indicator_list=TECH_INDICATORS,\n",
    "        sentiment_feature_list=[],\n",
    "        include_sentiment=False,\n",
    "        normalize_obs=True,\n",
    "        mode=mode,\n",
    "    )\n",
    "\n",
    "train_env = DummyVecEnv([lambda: create_env(train_data, \"train\")])\n",
    "\n",
    "exp_dir = f\"experiments/{EXPERIMENT_NAME}\"\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "os.makedirs(f\"{exp_dir}/logs\", exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nDevice: {device}\")\n",
    "print(f\"Training {TOTAL_TIMESTEPS:,} timesteps...\")\n",
    "print(f\"Estimated time: ~40 minutes on RTX 4090\\n\")\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    **TUNED_HYPERPARAMETERS,\n",
    "    policy_kwargs=POLICY_KWARGS,\n",
    "    verbose=1,\n",
    "    tensorboard_log=f\"{exp_dir}/logs\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "start_time = datetime.now()\n",
    "model.learn(total_timesteps=TOTAL_TIMESTEPS, progress_bar=True)\n",
    "training_time = datetime.now() - start_time\n",
    "\n",
    "model_path = f\"{exp_dir}/ppo_final_production.zip\"\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Time: {training_time}\")\n",
    "print(f\"Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Using Optuna-tuned hyperparameters with baseline (no sentiment) configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "sys.path.insert(0, \"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "EXPERIMENT_NAME = \"final_production_model\"\n",
    "TOTAL_TIMESTEPS = 1_500_000\n",
    "\n",
    "TUNED_HYPERPARAMETERS = {\n",
    "    \"learning_rate\": 0.000812,\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"gamma\": 0.992,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"ent_coef\": 0.0024,\n",
    "    \"vf_coef\": 0.428,\n",
    "    \"max_grad_norm\": 0.769,\n",
    "}\n",
    "\n",
    "POLICY_KWARGS = {\n",
    "    \"net_arch\": [256, 256]\n",
    "}\n",
    "\n",
    "ENV_CONFIG = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 100000,\n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.001,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"include_sentiment\": False,\n",
    "    \"normalize_obs\": True,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"  Timesteps: {TOTAL_TIMESTEPS:,}\")\n",
    "print(f\"  Sentiment: DISABLED (baseline)\")\n",
    "print(f\"  Learning Rate: {TUNED_HYPERPARAMETERS['learning_rate']}\")\n",
    "print(f\"  Network: {POLICY_KWARGS['net_arch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "sys.path.insert(0, \"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "from src.data.enhanced_processor import EnhancedDataProcessor\n",
    "\n",
    "processor = EnhancedDataProcessor(\n",
    "    price_path=\"data/processed_data.csv\",\n",
    "    sentiment_path=\"data/historical_sentiment_complete.csv\"\n",
    ")\n",
    "\n",
    "train_data, test_data = processor.get_train_test_split(\n",
    "    train_end=\"2024-06-30\",\n",
    "    test_start=\"2024-07-01\"\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(train_data)} records\")\n",
    "print(f\"Test: {len(test_data)} records\")\n",
    "print(f\"Train period: {train_data['date'].min()} to {train_data['date'].max()}\")\n",
    "print(f\"Test period: {test_data['date'].min()} to {test_data['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "sys.path.insert(0, \"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from src.env.enhanced_portfolio_env import EnhancedPortfolioEnv\n",
    "from src.data.enhanced_processor import EnhancedDataProcessor\n",
    "\n",
    "EXPERIMENT_NAME = \"final_production_model\"\n",
    "TOTAL_TIMESTEPS = 1_500_000\n",
    "\n",
    "TUNED_HYPERPARAMETERS = {\n",
    "    \"learning_rate\": 0.000812,\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"gamma\": 0.992,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"ent_coef\": 0.0024,\n",
    "    \"vf_coef\": 0.428,\n",
    "    \"max_grad_norm\": 0.769,\n",
    "}\n",
    "\n",
    "POLICY_KWARGS = {\"net_arch\": [256, 256]}\n",
    "\n",
    "processor = EnhancedDataProcessor(\n",
    "    price_path=\"data/processed_data.csv\",\n",
    "    sentiment_path=\"data/historical_sentiment_complete.csv\"\n",
    ")\n",
    "train_data, test_data = processor.get_train_test_split(\n",
    "    train_end=\"2024-06-30\",\n",
    "    test_start=\"2024-07-01\"\n",
    ")\n",
    "\n",
    "TECH_INDICATORS = [\n",
    "    'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30',\n",
    "    'close_30_sma', 'close_60_sma', 'vix', 'turbulence'\n",
    "]\n",
    "\n",
    "def create_env(data, mode=\"train\"):\n",
    "    return EnhancedPortfolioEnv(\n",
    "        df=data,\n",
    "        stock_dim=10,\n",
    "        hmax=100,\n",
    "        initial_amount=100000,\n",
    "        buy_cost_pct=0.001,\n",
    "        sell_cost_pct=0.001,\n",
    "        reward_scaling=1e-4,\n",
    "        tech_indicator_list=TECH_INDICATORS,\n",
    "        sentiment_feature_list=[],\n",
    "        include_sentiment=False,\n",
    "        normalize_obs=True,\n",
    "        mode=mode,\n",
    "    )\n",
    "\n",
    "train_env = DummyVecEnv([lambda: create_env(train_data, \"train\")])\n",
    "\n",
    "exp_dir = f\"experiments/{EXPERIMENT_NAME}\"\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "os.makedirs(f\"{exp_dir}/logs\", exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nDevice: {device}\")\n",
    "print(f\"Training {TOTAL_TIMESTEPS:,} timesteps...\")\n",
    "print(f\"Estimated time: ~40 minutes on RTX 4090\\n\")\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    **TUNED_HYPERPARAMETERS,\n",
    "    policy_kwargs=POLICY_KWARGS,\n",
    "    verbose=1,\n",
    "    tensorboard_log=f\"{exp_dir}/logs\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "start_time = datetime.now()\n",
    "model.learn(total_timesteps=TOTAL_TIMESTEPS, progress_bar=True)\n",
    "training_time = datetime.now() - start_time\n",
    "\n",
    "model_path = f\"{exp_dir}/ppo_final_production.zip\"\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Time: {training_time}\")\n",
    "print(f\"Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "sys.path.insert(0, \"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from src.env.enhanced_portfolio_env import EnhancedPortfolioEnv\n",
    "from src.data.enhanced_processor import EnhancedDataProcessor\n",
    "\n",
    "EXPERIMENT_NAME = \"final_production_model\"\n",
    "exp_dir = f\"experiments/{EXPERIMENT_NAME}\"\n",
    "model_path = f\"{exp_dir}/ppo_final_production.zip\"\n",
    "\n",
    "TECH_INDICATORS = [\n",
    "    'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30',\n",
    "    'close_30_sma', 'close_60_sma', 'vix', 'turbulence'\n",
    "]\n",
    "\n",
    "processor = EnhancedDataProcessor(\n",
    "    price_path=\"data/processed_data.csv\",\n",
    "    sentiment_path=\"data/historical_sentiment_complete.csv\"\n",
    ")\n",
    "train_data, test_data = processor.get_train_test_split(\n",
    "    train_end=\"2024-06-30\",\n",
    "    test_start=\"2024-07-01\"\n",
    ")\n",
    "\n",
    "test_env = EnhancedPortfolioEnv(\n",
    "    df=test_data,\n",
    "    stock_dim=10,\n",
    "    hmax=100,\n",
    "    initial_amount=100000,\n",
    "    buy_cost_pct=0.001,\n",
    "    sell_cost_pct=0.001,\n",
    "    reward_scaling=1e-4,\n",
    "    tech_indicator_list=TECH_INDICATORS,\n",
    "    sentiment_feature_list=[],\n",
    "    include_sentiment=False,\n",
    "    normalize_obs=True,\n",
    "    mode=\"test\",\n",
    ")\n",
    "\n",
    "model = PPO.load(model_path)\n",
    "\n",
    "print(\"Evaluating on test set...\")\n",
    "obs, _ = test_env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "stats = test_env.get_portfolio_stats()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL MODEL EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Return:    {stats['total_return']*100:.2f}%\")\n",
    "print(f\"Sharpe Ratio:    {stats['sharpe_ratio']:.3f}\")\n",
    "print(f\"Max Drawdown:    {stats['max_drawdown']*100:.2f}%\")\n",
    "print(f\"Total Trades:    {stats['total_trades']}\")\n",
    "print(f\"Final Value:     ${stats['final_value']:,.2f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = {\n",
    "    \"experiment_name\": EXPERIMENT_NAME,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"config\": {\n",
    "        \"include_sentiment\": False,\n",
    "        \"timesteps\": 1_500_000,\n",
    "        \"hyperparameters\": {\n",
    "            \"learning_rate\": 0.000812,\n",
    "            \"batch_size\": 64,\n",
    "            \"ent_coef\": 0.0024,\n",
    "            \"net_arch\": [256, 256],\n",
    "        }\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"sharpe_ratio\": stats['sharpe_ratio'],\n",
    "        \"total_return\": stats['total_return'],\n",
    "        \"max_drawdown\": stats['max_drawdown'],\n",
    "        \"total_trades\": stats['total_trades'],\n",
    "        \"final_value\": stats['final_value'],\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{exp_dir}/results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {exp_dir}/results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Package for Download\n",
    "\n",
    "Creates a zip file with the model and results for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "EXPERIMENT_NAME = \"final_production_model\"\n",
    "exp_dir = f\"experiments/{EXPERIMENT_NAME}\"\n",
    "\n",
    "output_zip = f\"/workspace/{EXPERIMENT_NAME}\"\n",
    "shutil.make_archive(output_zip, 'zip', exp_dir)\n",
    "\n",
    "zip_size = os.path.getsize(f\"{output_zip}.zip\") / 1024 / 1024\n",
    "print(f\"Created: {output_zip}.zip ({zip_size:.2f} MB)\")\n",
    "print(f\"\\nDownload this file and extract to your local project.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Copy Model for Paper Trading\n",
    "\n",
    "Also save the model in a standard location for paper trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "EXPERIMENT_NAME = \"final_production_model\"\n",
    "src_model = f\"experiments/{EXPERIMENT_NAME}/ppo_final_production.zip\"\n",
    "dst_model = \"models/ppo_final_production.zip\"\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "shutil.copy(src_model, dst_model)\n",
    "\n",
    "print(f\"Model copied to: {dst_model}\")\n",
    "print(f\"\\nUpdate your config.py MODEL_PATH to:\")\n",
    "print(f'MODEL_PATH = \"./models/ppo_final_production.zip\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
