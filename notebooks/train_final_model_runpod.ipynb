{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Production Model Training (RunPod)\n",
    "\n",
    "Train the final production model using:\n",
    "- **Baseline configuration** (no sentiment - best from ablation study)\n",
    "- **Optuna-tuned hyperparameters** (Sharpe 2.28)\n",
    "\n",
    "**Expected:** Sharpe ~1.6-2.0, Return ~45-55%, Drawdown <15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install dependencies (including tqdm and rich for progress bar)\n",
    "!pip install -q stable-baselines3[extra] gymnasium pandas numpy tqdm rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install dependencies\n",
    "!pip install -q stable-baselines3[extra] gymnasium pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train with OPTUNA SETTINGS (sentiment=True, normalize_obs=False)\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "sys.path.insert(0, \"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from src.env.enhanced_portfolio_env import EnhancedPortfolioEnv\n",
    "from src.data.enhanced_processor import EnhancedDataProcessor, ProcessorConfig\n",
    "\n",
    "# ============ CONFIGURATION ============\n",
    "EXPERIMENT_NAME = \"final_sentiment_model\"\n",
    "TOTAL_TIMESTEPS = 800_000  # More than Optuna's 300k for better generalization\n",
    "\n",
    "# Optuna Trial 21 hyperparameters (Sharpe 2.28)\n",
    "PPO_CONFIG = {\n",
    "    \"learning_rate\": 0.000812,\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"gamma\": 0.992,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"ent_coef\": 0.0024,\n",
    "    \"vf_coef\": 0.428,\n",
    "    \"max_grad_norm\": 0.769,\n",
    "}\n",
    "\n",
    "# Network architecture from Optuna\n",
    "POLICY_KWARGS = {\n",
    "    \"net_arch\": dict(pi=[256, 256], vf=[256, 256]),\n",
    "}\n",
    "\n",
    "# ============ LOAD DATA (same as Optuna) ============\n",
    "print(\"Loading data with Optuna settings...\")\n",
    "config = ProcessorConfig(normalize_features=True, normalization_window=60)\n",
    "processor = EnhancedDataProcessor(\n",
    "    price_path=\"data/processed_data.csv\",\n",
    "    sentiment_path=\"data/historical_sentiment_complete.csv\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Check date range and set split\n",
    "price_df = pd.read_csv('data/processed_data.csv')\n",
    "max_date = pd.to_datetime(price_df['date'].max())\n",
    "if max_date >= pd.to_datetime('2024-07-01'):\n",
    "    train_end = '2024-06-30'\n",
    "    test_start = '2024-07-01'\n",
    "else:\n",
    "    dates = sorted(price_df['date'].unique())\n",
    "    split_idx = int(len(dates) * 0.8)\n",
    "    train_end = dates[split_idx - 1]\n",
    "    test_start = dates[split_idx]\n",
    "    print(f\"Using 80/20 split: train_end={train_end}, test_start={test_start}\")\n",
    "\n",
    "train_df, test_df = processor.get_train_test_split(\n",
    "    train_end=train_end,\n",
    "    test_start=test_start,\n",
    ")\n",
    "feature_info = processor.get_feature_info()\n",
    "\n",
    "# Prepare data with day index\n",
    "def prepare_env_data(df):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "    dates = sorted(df['date'].unique())\n",
    "    date_to_day = {date: i for i, date in enumerate(dates)}\n",
    "    df['day'] = df['date'].map(date_to_day)\n",
    "    return df.set_index('day')\n",
    "\n",
    "train_data = prepare_env_data(train_df)\n",
    "test_data = prepare_env_data(test_df)\n",
    "\n",
    "print(f\"Train: {len(train_data)} records, {train_data.index.nunique()} days\")\n",
    "print(f\"Test: {len(test_data)} records, {test_data.index.nunique()} days\")\n",
    "print(f\"Tech indicators: {feature_info['tech_indicators']}\")\n",
    "print(f\"Sentiment features: {feature_info['sentiment_features']}\")\n",
    "\n",
    "# ============ CREATE ENVIRONMENT (OPTUNA SETTINGS) ============\n",
    "def make_env(data, mode=\"train\"):\n",
    "    env = EnhancedPortfolioEnv(\n",
    "        df=data,\n",
    "        stock_dim=feature_info['n_tickers'],\n",
    "        hmax=100,\n",
    "        initial_amount=100000,\n",
    "        buy_cost_pct=0.001,\n",
    "        sell_cost_pct=0.001,\n",
    "        reward_scaling=1e-4,\n",
    "        tech_indicator_list=feature_info['tech_indicators'],\n",
    "        sentiment_feature_list=feature_info['sentiment_features'],\n",
    "        include_sentiment=True,    # OPTUNA SETTING\n",
    "        normalize_obs=False,       # OPTUNA SETTING\n",
    "        print_verbosity=0,\n",
    "        mode=mode,\n",
    "    )\n",
    "    return Monitor(env)\n",
    "\n",
    "train_env = DummyVecEnv([lambda: make_env(train_data, \"train\")])\n",
    "\n",
    "# ============ TRAIN MODEL ============\n",
    "exp_dir = f\"experiments/{EXPERIMENT_NAME}\"\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nTraining {TOTAL_TIMESTEPS:,} timesteps on CUDA...\")\n",
    "print(\"Settings: sentiment=True, normalize_obs=False (Optuna config)\")\n",
    "print(f\"Estimated time: ~25-30 minutes\\n\")\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    **PPO_CONFIG,\n",
    "    policy_kwargs=POLICY_KWARGS,\n",
    "    verbose=1,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "start_time = datetime.now()\n",
    "model.learn(total_timesteps=TOTAL_TIMESTEPS, progress_bar=True)\n",
    "training_time = datetime.now() - start_time\n",
    "\n",
    "model_path = f\"{exp_dir}/ppo_sentiment_tuned.zip\"\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Time: {training_time}\")\n",
    "print(f\"Model: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Evaluate the new model\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "sys.path.insert(0, \"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from src.env.enhanced_portfolio_env import EnhancedPortfolioEnv\n",
    "from src.data.enhanced_processor import EnhancedDataProcessor, ProcessorConfig\n",
    "\n",
    "EXPERIMENT_NAME = \"final_sentiment_model\"\n",
    "exp_dir = f\"experiments/{EXPERIMENT_NAME}\"\n",
    "model_path = f\"{exp_dir}/ppo_sentiment_tuned.zip\"\n",
    "\n",
    "# Load data (same settings as training)\n",
    "config = ProcessorConfig(normalize_features=True, normalization_window=60)\n",
    "processor = EnhancedDataProcessor(\n",
    "    price_path=\"data/processed_data.csv\",\n",
    "    sentiment_path=\"data/historical_sentiment_complete.csv\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Check date range\n",
    "price_df = pd.read_csv('data/processed_data.csv')\n",
    "max_date = pd.to_datetime(price_df['date'].max())\n",
    "if max_date >= pd.to_datetime('2024-07-01'):\n",
    "    train_end = '2024-06-30'\n",
    "    test_start = '2024-07-01'\n",
    "else:\n",
    "    dates = sorted(price_df['date'].unique())\n",
    "    split_idx = int(len(dates) * 0.8)\n",
    "    train_end = dates[split_idx - 1]\n",
    "    test_start = dates[split_idx]\n",
    "\n",
    "_, test_df = processor.get_train_test_split(train_end=train_end, test_start=test_start)\n",
    "feature_info = processor.get_feature_info()\n",
    "\n",
    "def prepare_env_data(df):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "    dates = sorted(df['date'].unique())\n",
    "    date_to_day = {date: i for i, date in enumerate(dates)}\n",
    "    df['day'] = df['date'].map(date_to_day)\n",
    "    return df.set_index('day')\n",
    "\n",
    "test_data = prepare_env_data(test_df)\n",
    "\n",
    "# Create test environment (SAME settings as training)\n",
    "test_env = EnhancedPortfolioEnv(\n",
    "    df=test_data,\n",
    "    stock_dim=feature_info['n_tickers'],\n",
    "    hmax=100,\n",
    "    initial_amount=100000,\n",
    "    buy_cost_pct=0.001,\n",
    "    sell_cost_pct=0.001,\n",
    "    reward_scaling=1e-4,\n",
    "    tech_indicator_list=feature_info['tech_indicators'],\n",
    "    sentiment_feature_list=feature_info['sentiment_features'],\n",
    "    include_sentiment=True,    # OPTUNA SETTING\n",
    "    normalize_obs=False,       # OPTUNA SETTING\n",
    "    print_verbosity=0,\n",
    "    mode=\"test\",\n",
    ")\n",
    "\n",
    "# Load and evaluate\n",
    "model = PPO.load(model_path)\n",
    "print(\"Evaluating on test set...\")\n",
    "\n",
    "obs, _ = test_env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs.reshape(1, -1), deterministic=True)\n",
    "    obs, _, done, _, _ = test_env.step(action[0])\n",
    "\n",
    "stats = test_env.get_portfolio_stats()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EVALUATION RESULTS (New Model - 800k steps)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Sharpe Ratio:  {stats['sharpe_ratio']:.3f}\")\n",
    "print(f\"Total Return:  {stats['total_return']*100:.2f}%\")\n",
    "print(f\"Max Drawdown:  {stats['max_drawdown']*100:.2f}%\")\n",
    "print(f\"Total Trades:  {stats['total_trades']}\")\n",
    "print(f\"Final Value:   ${stats['final_value']:,.2f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Compare with previous best\n",
    "print(f\"\\nComparison with ppo_enhanced_tuned (Sharpe 1.10):\")\n",
    "if stats['sharpe_ratio'] > 1.10:\n",
    "    print(f\"  IMPROVEMENT: +{(stats['sharpe_ratio'] - 1.10):.3f} Sharpe\")\n",
    "else:\n",
    "    print(f\"  No improvement: {(stats['sharpe_ratio'] - 1.10):.3f} Sharpe\")\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    \"experiment_name\": EXPERIMENT_NAME,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"config\": {\n",
    "        \"include_sentiment\": True,\n",
    "        \"normalize_obs\": False,\n",
    "        \"timesteps\": 800_000,\n",
    "        \"learning_rate\": 0.000812,\n",
    "        \"batch_size\": 64,\n",
    "        \"net_arch\": [256, 256],\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"sharpe_ratio\": float(stats['sharpe_ratio']),\n",
    "        \"total_return\": float(stats['total_return']),\n",
    "        \"max_drawdown\": float(stats['max_drawdown']),\n",
    "        \"total_trades\": int(stats['total_trades']),\n",
    "        \"final_value\": float(stats['final_value']),\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{exp_dir}/results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"\\nResults saved to {exp_dir}/results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Package for Download\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "EXPERIMENT_NAME = \"final_sentiment_model\"\n",
    "exp_dir = f\"experiments/{EXPERIMENT_NAME}\"\n",
    "\n",
    "# Copy to models folder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "shutil.copy(f\"{exp_dir}/ppo_sentiment_tuned.zip\", \"models/ppo_sentiment_tuned.zip\")\n",
    "\n",
    "# Create download zip\n",
    "output_zip = f\"/workspace/{EXPERIMENT_NAME}\"\n",
    "shutil.make_archive(output_zip, 'zip', exp_dir)\n",
    "\n",
    "print(f\"Model copied to: models/ppo_sentiment_tuned.zip\")\n",
    "print(f\"Download: {output_zip}.zip ({os.path.getsize(f'{output_zip}.zip')/1024/1024:.1f} MB)\")\n",
    "print(f\"\\nIf this model is better, update config.py:\")\n",
    "print('MODEL_PATH = \"./models/ppo_sentiment_tuned.zip\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Package for Download\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "os.chdir(\"/workspace/enhanced-rl-portfolio\")\n",
    "\n",
    "EXPERIMENT_NAME = \"final_production_model\"\n",
    "exp_dir = f\"experiments/{EXPERIMENT_NAME}\"\n",
    "\n",
    "# Copy to models folder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "shutil.copy(f\"{exp_dir}/ppo_final_production.zip\", \"models/ppo_final_production.zip\")\n",
    "\n",
    "# Create download zip\n",
    "output_zip = f\"/workspace/{EXPERIMENT_NAME}\"\n",
    "shutil.make_archive(output_zip, 'zip', exp_dir)\n",
    "\n",
    "print(f\"Model copied to: models/ppo_final_production.zip\")\n",
    "print(f\"Download: {output_zip}.zip ({os.path.getsize(f'{output_zip}.zip')/1024/1024:.1f} MB)\")\n",
    "print(f\"\\nUpdate config.py:\")\n",
    "print('MODEL_PATH = \"./models/ppo_final_production.zip\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
