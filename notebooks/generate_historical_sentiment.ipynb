{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Sentiment Generation with FinBERT\n",
    "\n",
    "This notebook runs FinBERT inference on historical news headlines to generate sentiment scores.\n",
    "\n",
    "**Requirements:**\n",
    "- GPU runtime recommended (Runtime > Change runtime type > T4 GPU)\n",
    "- ~5 minutes for 100k headlines on T4 GPU\n",
    "\n",
    "**Usage:**\n",
    "1. Upload your `news_combined.csv` to Colab\n",
    "2. Run all cells\n",
    "3. Download `historical_sentiment.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers torch pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FinBERT model\n",
    "print(\"Loading FinBERT model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_batch(texts, batch_size=32):\n",
    "    \"\"\"Run FinBERT inference on a batch of texts.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = F.softmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        # FinBERT: positive=0, negative=1, neutral=2\n",
    "        label_map = {0: \"positive\", 1: \"negative\", 2: \"neutral\"}\n",
    "        \n",
    "        for prob in probs:\n",
    "            pred_idx = prob.argmax().item()\n",
    "            confidence = prob[pred_idx].item()\n",
    "            \n",
    "            # Weighted score: positive=1, negative=-1, neutral=0\n",
    "            score = prob[0].item() * 1.0 + prob[1].item() * -1.0 + prob[2].item() * 0.0\n",
    "            \n",
    "            results.append({\n",
    "                \"sentiment_score\": score,\n",
    "                \"sentiment_label\": label_map[pred_idx],\n",
    "                \"confidence\": confidence,\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your news file or use sample data\n",
    "# Option 1: Upload file\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# news_df = pd.read_csv(list(uploaded.keys())[0])\n",
    "\n",
    "# Option 2: Load from path\n",
    "NEWS_FILE = \"news_combined.csv\"  # Update this path\n",
    "\n",
    "try:\n",
    "    news_df = pd.read_csv(NEWS_FILE)\n",
    "    print(f\"Loaded {len(news_df)} headlines\")\n",
    "    print(news_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {NEWS_FILE}\")\n",
    "    print(\"Please upload your news file or update the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sentiment inference\n",
    "headlines = news_df[\"headline\"].fillna(\"\").tolist()\n",
    "print(f\"Processing {len(headlines)} headlines...\")\n",
    "\n",
    "results = predict_sentiment_batch(headlines, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Add results to dataframe\n",
    "news_df[\"sentiment_score\"] = [r[\"sentiment_score\"] for r in results]\n",
    "news_df[\"sentiment_label\"] = [r[\"sentiment_label\"] for r in results]\n",
    "news_df[\"sentiment_confidence\"] = [r[\"confidence\"] for r in results]\n",
    "\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(news_df[\"sentiment_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to daily sentiment per ticker\n",
    "def aggregate_daily(df):\n",
    "    grouped = df.groupby([\"date\", \"ticker\"])\n",
    "    \n",
    "    daily = grouped.agg({\n",
    "        \"sentiment_score\": [\"mean\", \"std\", \"count\"],\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily.columns = [\"date\", \"ticker\", \"sentiment_score\", \"sentiment_std\", \"news_count\"]\n",
    "    daily[\"sentiment_std\"] = daily[\"sentiment_std\"].fillna(0)\n",
    "    \n",
    "    # Compute ratios\n",
    "    def compute_ratios(group):\n",
    "        scores = group[\"sentiment_score\"]\n",
    "        pos = (scores > 0.1).sum() / len(scores) if len(scores) > 0 else 0\n",
    "        neg = (scores < -0.1).sum() / len(scores) if len(scores) > 0 else 0\n",
    "        return pd.Series({\"positive_ratio\": pos, \"negative_ratio\": neg})\n",
    "    \n",
    "    ratios = df.groupby([\"date\", \"ticker\"]).apply(compute_ratios, include_groups=False).reset_index()\n",
    "    daily = daily.merge(ratios, on=[\"date\", \"ticker\"])\n",
    "    \n",
    "    return daily.sort_values([\"date\", \"ticker\"]).reset_index(drop=True)\n",
    "\n",
    "daily_sentiment = aggregate_daily(news_df)\n",
    "print(f\"\\nDaily sentiment records: {len(daily_sentiment)}\")\n",
    "print(daily_sentiment.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "OUTPUT_FILE = \"historical_sentiment.csv\"\n",
    "daily_sentiment.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Saved to {OUTPUT_FILE}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SENTIMENT GENERATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Headlines processed: {len(news_df)}\")\n",
    "print(f\"Daily records: {len(daily_sentiment)}\")\n",
    "print(f\"Date range: {daily_sentiment['date'].min()} to {daily_sentiment['date'].max()}\")\n",
    "print(f\"Tickers: {daily_sentiment['ticker'].nunique()}\")\n",
    "print(f\"Unique dates: {daily_sentiment['date'].nunique()}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results (Colab)\n",
    "# from google.colab import files\n",
    "# files.download(OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
